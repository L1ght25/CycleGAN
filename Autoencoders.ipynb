{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Autoencoders",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shp7mzVZrvpg"
      },
      "source": [
        "Был выбран CycleGAN.\n",
        "Вначале реализуется своя архитектура на известной задаче яблоки/апельсины."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1x4Sd-zb04U"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "from time import time\n",
        "import os\n",
        "import errno\n",
        "import torchvision.utils as vutils\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import sys\n",
        "from torch.autograd import Variable\n",
        "import itertools\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "import glob\n",
        "from torch.utils.data import Dataset\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6zePAP3yV02"
      },
      "source": [
        "import pickle\n",
        "from skimage import io\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from pathlib import Path\n",
        "\n",
        "from multiprocessing.pool import ThreadPool\n",
        "import torch.nn as nn\n",
        "\n",
        "from matplotlib import colors, pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYoUWBFaSrcx"
      },
      "source": [
        "#Шаманство с датой"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctpEyDSrQ_aU",
        "outputId": "e38fa3fb-f5a4-4a40-918e-ba62567209f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIsa8TG3NtbL"
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/Asian2.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-QA3AyiRjP4"
      },
      "source": [
        " !unzip /content/drive/My\\ Drive/European1.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3WPP0PJrm2g"
      },
      "source": [
        "def for_show(inp, mode = 'numpy'): # Для вывода картинок во время трейна\n",
        "  if mode != 'numpy':\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "  else:\n",
        "    inp = inp.transpose((1, 2, 0))\n",
        "  mean = np.array((0.5,0.5,0.5))\n",
        "  std = np.array((0.5,0.5,0.5))\n",
        "  inp = std * inp + mean\n",
        "  inp = np.clip(inp, 0, 1)\n",
        "  return inp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA2zxU_QbzNO"
      },
      "source": [
        "def imshow(inp, title=None, plt_ax=plt, default=False): # Функция вывода изображения\n",
        "\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array((0.5,0.5,0.5))\n",
        "    std = np.array((0.5,0.5,0.5))\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt_ax.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt_ax.set_title(title)\n",
        "    plt_ax.grid(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1ec1GYT40g2"
      },
      "source": [
        "train_as = Path('/content/Asian1')\n",
        "train_eu = Path('/content/European1')\n",
        "\n",
        "as_files = sorted(list(train_as.rglob('*.png')))\n",
        "eu_files = sorted(list(train_eu.rglob('*.png')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IHBnyw75OzA"
      },
      "source": [
        "asian = []\n",
        "european = []\n",
        "for filename in as_files:\n",
        "  asian.append(str(filename))\n",
        "\n",
        "for filename in eu_files:\n",
        "  european.append(str(filename)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qDeYQug4cqr"
      },
      "source": [
        "class MakeDataset(Dataset): # Подготовка датасета\n",
        "\n",
        "    def __init__(self, files, files1 = None, mode = None, mode_sample = None):\n",
        "        super().__init__()\n",
        "        # список файлов для загрузки\n",
        "        self.files = sorted(files)\n",
        "        self.len_ = len(self.files)\n",
        "        self.mode = mode\n",
        "        if self.mode == None:\n",
        "            self.files1 = sorted(files1)\n",
        "            self.len1_ = len(self.files1)\n",
        "        self.mode_sample = mode_sample\n",
        "                      \n",
        "    def __len__(self):\n",
        "        return self.len_\n",
        "      \n",
        "    def load_sample(self, file):\n",
        "        image = Image.open(file)\n",
        "        image.load()\n",
        "        return image\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "        ])\n",
        "        x = self.load_sample(self.files[index % len(self.files)])\n",
        "        x = self._prepare_sample(x)\n",
        "        x = np.array(x / 255, dtype='float32')\n",
        "        x = transform(x)\n",
        "        if self.mode == None:\n",
        "            if self.mode_sample == 'rand':\n",
        "                y = self.load_sample(self.files1[random.randint(0, len(self.files1) - 1)])\n",
        "            else:\n",
        "                y = self.load_sample(self.files1[index % len(self.files)])\n",
        "            y = self._prepare_sample(y)\n",
        "            y = np.array(y / 255, dtype='float32')\n",
        "            y = transform(y)\n",
        "\n",
        "            return x, y\n",
        "        else:\n",
        "            return x\n",
        "        \n",
        "    def _prepare_sample(self, image):\n",
        "        image = image.resize((64, 64))\n",
        "        return np.array(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxw5pnmC-rEG"
      },
      "source": [
        "def prov(file): # В датасете есть чёрно-белые картинки, поэтому отбрасываем их\n",
        "  transform = transforms.ToTensor()\n",
        "  image = Image.open(file)\n",
        "  image.load()\n",
        "  image = np.array(image.resize((64, 64)))\n",
        "  image = np.array(image / 255, dtype='float32')\n",
        "  image = transform(image)\n",
        "  return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-FWR0_zXdII"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyQf7Meguj5v",
        "outputId": "06c866c4-2f37-4c11-9d49-51b26ebe034c"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fL4VnyiYYRG"
      },
      "source": [
        "def plot_gallery(images, h, w, n_row=3, n_col=6):\n",
        "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
        "    plt.figure(figsize=(1.5 * n_col, 1.7 * n_row))\n",
        "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
        "    #images = np.array(images, dtype='float32')\n",
        "    for i in range(n_row * n_col):\n",
        "        plt.subplot(n_row, n_col, i + 1)\n",
        "        inp = np.array(images[i])\n",
        "        #inp.transpose((1, 2, 0))\n",
        "        mean = np.array([0.5, 0.5, 0.5])\n",
        "        std = np.array([0.5, 0.5, 0.5])\n",
        "        inp = std * inp + mean\n",
        "        try:\n",
        "            plt.imshow(inp, cmap=plt.cm.gray, vmin=-1, vmax=1, interpolation='nearest')\n",
        "            plt.xticks(())\n",
        "            plt.yticks(())\n",
        "        except:\n",
        "            pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00qPo50xabbB"
      },
      "source": [
        "def To_tens(dataset):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    new_set = []\n",
        "    for i in range(len(dataset)):\n",
        "        x = np.array(dataset[i].transpose((0, 1, 2)) / 255, dtype='float32')\n",
        "        new_set.append(transform(x))\n",
        "    return torch.stack(new_set).permute(0, 2, 3, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcbOh6soZdr5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train = asian[0:1200]\n",
        "X_val = asian[1201:1342]\n",
        "Y_train = european[0:1200]\n",
        "Y_val = european[1201:1342]\n",
        "train_dataset = MakeDataset(X_train, Y_train)\n",
        "test_dataset = MakeDataset(X_val, Y_val, mode = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tmmgZ7XLFbR"
      },
      "source": [
        "class encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(encoder, self).__init__()\n",
        "        self.linear = nn.Linear(64*64*3, 2048)\n",
        "        self.bn = nn.BatchNorm1d(2048)\n",
        "        self.linear1 = nn.Linear(2048, 1024)\n",
        "        self.bn1 = nn.BatchNorm1d(1024)\n",
        "        self.linear2 = nn.Linear(1024, 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.mu = nn.Linear(256, 100)\n",
        "        # self.bn3 = nn.BatchNorm1d(100)\n",
        "        self.var = nn.Linear(256, 100)\n",
        "        # self.bn4 = nn.BatchNorm1d(100)\n",
        "\n",
        "    def gaussian_sampler(self, mu, logsigma):\n",
        "            if self.training:\n",
        "                std = logsigma.exp_()\n",
        "                eps = Variable(std.data.new(std.size()).normal_())\n",
        "                return eps.mul(std).add_(mu)\n",
        "            else:\n",
        "                return mu\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden = F.leaky_relu(self.bn(self.linear(x)))\n",
        "        hidden1 = F.leaky_relu(self.bn1(self.linear1(hidden)))\n",
        "        hidden2 = F.leaky_relu(self.bn2(self.linear2(hidden1)))\n",
        "        mu = self.mu(hidden2)\n",
        "        logsigma = self.var(hidden2)\n",
        "        latent = self.gaussian_sampler(mu, logsigma)\n",
        "        \n",
        "        return mu, logsigma, latent\n",
        "\n",
        "class decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(decoder, self).__init__()\n",
        "        self.latent_to_hidden = nn.Linear(100, 256)\n",
        "        self.bn3 = nn.BatchNorm1d(256)\n",
        "        self.hidden_to_out = nn.Linear(256, 1024)\n",
        "        self.bn4 = nn.BatchNorm1d(1024)\n",
        "        self.hidden_to_out1 = nn.Linear(1024, 2048)\n",
        "        self.bn5 = nn.BatchNorm1d(2048)\n",
        "        self.hidden_to_out2 = nn.Linear(2048, 64*64*3)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, z):\n",
        "\n",
        "          # z = self.gaussian_sampler(mu, logsigma)\n",
        "\n",
        "          x = F.leaky_relu(self.bn3(self.latent_to_hidden(z)))\n",
        "          x = F.leaky_relu(self.bn4(self.hidden_to_out(x)))\n",
        "          x = F.leaky_relu(self.bn5(self.hidden_to_out1(x)))\n",
        "          reconstruction = F.sigmoid(self.hidden_to_out2(x))\n",
        "          \n",
        "        \n",
        "          return reconstruction\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "\n",
        "    def __init__(self, enc, dec):\n",
        "            super().__init__()\n",
        "\n",
        "            self.enc = enc\n",
        "            self.dec = dec\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "            # encode\n",
        "            mu, logsigma, latent = self.enc(x)\n",
        "            # latent = self.gaussian_sampler(mu, logsigma)\n",
        "\n",
        "            # decode\n",
        "            predicted = self.dec(latent)\n",
        "            return predicted, mu, logsigma\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJZw6n2PXSBF"
      },
      "source": [
        "def KL_divergence(mu, logsigma):\n",
        "    \"\"\"\n",
        "    часть функции потерь, которая отвечает за \"близость\" латентных представлений разных людей\n",
        "    \"\"\"\n",
        "    loss = -0.5 * torch.mean(1 + 2*logsigma - mu**2 - torch.exp(2*logsigma))\n",
        "    return loss\n",
        "\n",
        "def log_likelihood(reconstruction, x):\n",
        "    \"\"\"\n",
        "    часть функции потерь, которая отвечает за качество реконструкции (как mse в обычном autoencoder)\n",
        "    \"\"\"\n",
        "    loss = F.binary_cross_entropy\n",
        "    return loss(reconstruction, x)\n",
        "\n",
        "def loss_vae(x, mu, logsigma, reconstruction):\n",
        "    return 0.5 *(KL_divergence(mu, logsigma) / (64*64)+log_likelihood(reconstruction, x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MzTkjuSXVSD"
      },
      "source": [
        "criterion = loss_vae\n",
        "encoder = encoder()\n",
        "decoder = decoder()\n",
        "vae = VAE(encoder, decoder).to(device)\n",
        "\n",
        "\n",
        "optim = torch.optim.Adam(vae.parameters(), lr = 0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EZaFJUdXzEZ"
      },
      "source": [
        "from tqdm import tqdm \n",
        "\n",
        "def train_vae(train, val, epochs, autoencoder, loss_fn, optim):\n",
        "    train_loader = DataLoader(train, batch_size=8, shuffle=False)\n",
        "    \n",
        "    test_loader = DataLoader(val, batch_size=8, shuffle=False)\n",
        "    trainl = []\n",
        "    vall = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # X_val = next(iter(val)\n",
        "        recon = []\n",
        "        train_loss = 0.0\n",
        "        val_loss = 0.0\n",
        "        # print('* Epoch %d/%d' % (epoch+1, epochs))\n",
        "        \n",
        "        autoencoder.train()\n",
        "        \n",
        "        # encoder.train()\n",
        "        # decoder.train()\n",
        "      \n",
        "\n",
        "        for X_batch, Y_batch in train_loader:\n",
        "\n",
        "          \n",
        "\n",
        "            X_batch = X_batch.to(device)\n",
        "            X_batch = X_batch.view(X_batch.size(0), 64*64*3)\n",
        "            optim.zero_grad()\n",
        "            # code = encoder(X_batch)\n",
        "            # rec = decoder(code)\n",
        "            rec, mu, log = autoencoder(X_batch)\n",
        "\n",
        "\n",
        "            loss = loss_fn(torch.clamp(X_batch, 0, 1), mu, log, rec)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "          \n",
        "\n",
        "            train_loss += loss.item()\n",
        "        trainl.append(train_loss / len(train))\n",
        "\n",
        "        torch.save(autoencoder.state_dict(), 'wheights.pt')\n",
        "\n",
        "\n",
        "\n",
        "        # print('loss: %f' % train_loss)\n",
        "        autoencoder.eval()\n",
        "        # encoder.eval()\n",
        "        # decoder.eval()\n",
        "        for X_val, Y_batch in test_loader:\n",
        "            X_val = X_val.to(device)\n",
        "            X_val = X_val.view(X_val.size(0), 64*64*3)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                # clear_output(wait=True)\n",
        "                # latent_code = encoder(X_val)\n",
        "                # reconstruction = decoder(latent_code)\n",
        "                reconstruction, muu, logsigma =  autoencoder(X_val)\n",
        "                # X_val = X_val.detach().to(device).numpy().reshape(X_val.size(0),45,45, 3)\n",
        "                # reconstruction = reconstruction.detach().to(device).numpy().reshape(reconstruction.size(0), 45, 45, 3)\n",
        "                # plot_gallery([X_val.astype(np.uint8), reconstruction.astype(np.uint8)], IMAGE_H, IMAGE_W, n_row=1, n_col=2)\n",
        "                loss = loss_fn(torch.clamp(X_val, 0, 1), muu, logsigma, reconstruction)\n",
        "                reconstruction = reconstruction.view(X_val.size(0), 3, 64, 64)\n",
        "                # X_val = X_val.view(reconstruction.size(0), 3, 256, 256)\n",
        "\n",
        "            recon.append(reconstruction)\n",
        "            val_loss += loss.item()\n",
        "        vall.append(val_loss / len(val))\n",
        "        clear_output(wait=True)\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "          # plot_gallery([np.array(val[k][0]), np.array(recon[0][k].detach().cpu())], h = 256, w = 256, n_row=1, n_col=2)\n",
        "        fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(8, 8), \\\n",
        "                        sharey=True, sharex=True)\n",
        "        for fig_x in ax.flatten():\n",
        "              im_val = test_dataset[0][0]\n",
        "              imshow(recon[1][0].detach().cpu(), plt_ax=fig_x)\n",
        "\n",
        "        fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(8, 8), \\\n",
        "                        sharey=True, sharex=True)\n",
        "        for fig_x in ax.flatten():\n",
        "              im_val = test_dataset[0][0]\n",
        "              # imshow(im_val.reshape(256, 256, 3).detach().cpu(), plt_ax=fig_x)\n",
        "              imshow(im_val.detach().cpu(), plt_ax=fig_x)\n",
        "              # imshow(recon[1][0].detach().cpu(), plt_ax=fig_x)\n",
        "        plt.show()\n",
        "\n",
        "        plt.plot(range(len(trainl)), trainl, label ='train')\n",
        "        plt.plot(range(len(vall)), vall, label ='val')\n",
        "        plt.suptitle('%d / %d - loss_train: %f, loss_val: %f' % (epoch+1, epochs, trainl[epoch], vall[epoch]))\n",
        "        # plt.suptitle('%d / %d - loss_train: %f, loss_val: %f' % (epoch+1, \\\n",
        "                                                                #  epochs, trainl[epoch], vall[epoch]))\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZQUKUa6YakV"
      },
      "source": [
        "train_vae(train_dataset, test_dataset, 20, vae, criterion, optim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7MeHp-xYztiv"
      },
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDscOmOg0zQ"
      },
      "source": [
        "criterion1 = loss_vae\n",
        "encoder1 = encoder()\n",
        "decoder1 = decoder()\n",
        "vae1 = VAE(encoder1, decoder1).to(device)\n",
        "\n",
        "\n",
        "optim1 = torch.optim.Adam(vae1.parameters(), lr = 0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--A2mPdVg-DK"
      },
      "source": [
        "def train_vae1(train, val, epochs, autoencoder, loss_fn, optim):\n",
        "    train_loader = DataLoader(train, batch_size=8, shuffle=False)\n",
        "    \n",
        "    test_loader = DataLoader(val, batch_size=8, shuffle=False)\n",
        "    trainl = []\n",
        "    vall = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # X_val = next(iter(val)\n",
        "        recon = []\n",
        "        train_loss = 0.0\n",
        "        val_loss = 0.0\n",
        "        # print('* Epoch %d/%d' % (epoch+1, epochs))\n",
        "        \n",
        "        autoencoder.train()\n",
        "        \n",
        "        # encoder.train()\n",
        "        # decoder.train()\n",
        "      \n",
        "\n",
        "        for X_batch, Y_batch in train_loader:\n",
        "\n",
        "          \n",
        "\n",
        "            Y_batch = Y_batch.to(device)\n",
        "            Y_batch = Y_batch.view(Y_batch.size(0), 64*64*3)\n",
        "            optim.zero_grad()\n",
        "            # code = encoder(X_batch)\n",
        "            # rec = decoder(code)\n",
        "            rec, mu, log = autoencoder(Y_batch)\n",
        "\n",
        "\n",
        "            loss = loss_fn(torch.clamp(Y_batch, 0, 1), mu, log, rec)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "          \n",
        "\n",
        "            train_loss += loss.item()\n",
        "        trainl.append(train_loss / len(train))\n",
        "\n",
        "        torch.save(autoencoder.state_dict(), 'wheights1.pt')\n",
        "\n",
        "\n",
        "\n",
        "        # print('loss: %f' % train_loss)\n",
        "        autoencoder.eval()\n",
        "        # encoder.eval()\n",
        "        # decoder.eval()\n",
        "        for X_val, Y_val in test_loader:\n",
        "            Y_val = Y_val.to(device)\n",
        "            Y_val = Y_val.view(Y_val.size(0), 64*64*3)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                # clear_output(wait=True)\n",
        "                # latent_code = encoder(X_val)\n",
        "                # reconstruction = decoder(latent_code)\n",
        "                reconstruction, muu, logsigma =  autoencoder(Y_val)\n",
        "                # X_val = X_val.detach().to(device).numpy().reshape(X_val.size(0),45,45, 3)\n",
        "                # reconstruction = reconstruction.detach().to(device).numpy().reshape(reconstruction.size(0), 45, 45, 3)\n",
        "                # plot_gallery([X_val.astype(np.uint8), reconstruction.astype(np.uint8)], IMAGE_H, IMAGE_W, n_row=1, n_col=2)\n",
        "                loss = loss_fn(torch.clamp(Y_val, 0, 1), muu, logsigma, reconstruction)\n",
        "                reconstruction = reconstruction.view(Y_val.size(0), 3, 64, 64)\n",
        "                # X_val = X_val.view(reconstruction.size(0), 3, 256, 256)\n",
        "\n",
        "            recon.append(reconstruction)\n",
        "            val_loss += loss.item()\n",
        "        vall.append(val_loss / len(val))\n",
        "        clear_output(wait=True)\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "          # plot_gallery([np.array(val[k][0]), np.array(recon[0][k].detach().cpu())], h = 256, w = 256, n_row=1, n_col=2)\n",
        "        fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(8, 8), \\\n",
        "                        sharey=True, sharex=True)\n",
        "        for fig_x in ax.flatten():\n",
        "              im_val = test_dataset[0][0]\n",
        "              imshow(recon[1][1].detach().cpu(), plt_ax=fig_x)\n",
        "\n",
        "        fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(8, 8), \\\n",
        "                        sharey=True, sharex=True)\n",
        "        for fig_x in ax.flatten():\n",
        "              im_val = test_dataset[30][1]\n",
        "              imshow(im_val.detach().cpu(), plt_ax=fig_x)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        plt.plot(range(len(trainl)), trainl, label ='train')\n",
        "        plt.plot(range(len(vall)), vall, label ='val')\n",
        "        plt.suptitle('%d / %d - loss_train: %f, loss_val: %f' % (epoch+1, epochs, trainl[epoch], vall[epoch]))\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqQR7Ydvhu_i"
      },
      "source": [
        "train_vae1(train_dataset, test_dataset, 20, vae1, criterion1, optim1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}